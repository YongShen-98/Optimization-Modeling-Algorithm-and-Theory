{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和线搜索类似，都是借助泰勒展开。但是在线搜索中，我们先用近似模型求出下降方向，然后再给定步长。但是在信頼域中，我们直接在一个有界的区域求解这个近似模型，然后迭代到下一个点，这种算法是同时找到步长和方向。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 算法框架\n",
    "$$f(x^{k}+d) = f(x^k) + \\nabla f(x^k)^Td + \\frac{1}{2}d^T\\nabla^2f(x^k + td)d$$\n",
    "$$m_k(d) = f(x^k) + \\nabla f(x^k)^Td + \\frac{1}{2}d^TB^kd$$\n",
    "其中$B^k$是海瑟矩阵或者海瑟矩阵的近似矩阵。我们这里是在一个小的范围内使用泰勒展开近似：\n",
    "$$\\Omega_k = \\{x^k + d \\quad|\\quad ||d|| \\leq \\Delta_k\\}$$\n",
    "其实就是每一步的迭代都需要求解如下子问题：\n",
    "$$\\min_{d\\in R^n}m_{k}(d),\\quad s.t. \\quad ||d||\\leq\\Delta_k \\tag{6.6.2}$$           "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给一个可以用来衡量近似程度的标准：\n",
    "$$\\rho_k = \\frac{f(x^k) - f(x^k + d^k)}{m_k(0) - m_k(d^k)}\\tag{6.6.3}$$\n",
    "接近1了，我们可以扩大$\\Delta_k$，反之则缩小。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](1.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般情况下，$\\bar{\\rho_1}=0.25,\\bar{\\rho_2}=0.75,\\gamma_1=0.25,\\gamma_2=2$。接下讨论关键问题：如何求解信頼域子问题？\n",
    "### 信頼域子问题求解"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 迭代法\n",
    "首先我们有如下定理：\n",
    "$d^{*}$是信頼域子问题\n",
    "$$\\min\\quad m(d)=f+g^Td+\\frac{1}{2}d^TBd$$\n",
    "的全局最小解当且仅当$d^{*}$是可行的并且存在$\\lambda\\geq 0$使得\n",
    "$$(B+\\lambda I)d^{n}=-g,\\quad \\lambda(\\Delta-||d^{n}||)=0,\\quad(B+\\lambda I)\\geq 0$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 截断共轭梯度法\n",
    "找到问题的近似解，先回顾一下标准的共轭梯度迭代：\n",
    "对于一个二次极小话问题\n",
    "$$\\min_{d} q(s) = g^Ts+\\frac{1}{2}s^TBs$$\n",
    "给定初值$s^0=0,r^{0}=g,p^{0}=-g,$共轭梯度法的迭代过程为\n",
    "$$\\alpha_{k+1}=\\frac{||r^k||^2}{(q^k)^TBq^k},\\\\\n",
    "s^{k+1}=s^k+\\alpha_kp^k,\\\\\n",
    "r^{k+1}=r^{k}+\\alpha_{k}Bp^{k},\\\\\n",
    "\\beta_{k}=\\frac{||r^{k+1}||^2}{||r^k||^2},\\\\\n",
    "p^{k+1}=-r^{k+1}+\\beta p^{k}$$\n",
    "其中得到的迭代序列$\\{s^k\\}$最终的输出就是二次极小化问题的，它的终止条件就是看$||r^k||$是不是足够小。\n",
    "\n",
    "截断共轭法需要考虑矩阵$B$不是正定矩阵的情况"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 应用举例\n",
    "#### 同样考虑逻辑回归问题\n",
    "$$\\min_{x}\\quad \\frac{1}{m}\\sum_{i=1}^{m}ln(1+exp(-b_{i}a_{i}^Tx))+\\lambda||x||_2^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "m = 5\n",
    "n = 5\n",
    "A = np.random.randint(0, 10, (m,n))\n",
    "B = np.random.randint(0, 10, m)\n",
    "Lambda = 1/(100*m)\n",
    "\n",
    "def sum(x):\n",
    "    s = 0\n",
    "    for i in range(m):\n",
    "        s += np.log(1+np.exp(-B[i]*A[i]@x))\n",
    "    return s\n",
    "f = lambda x : (1/m)*sum(x) + Lambda*x@x\n",
    "\n",
    "def grad_sum(x):\n",
    "    s = 0\n",
    "    for i in range(m):\n",
    "        s += (1 - 1/(1+np.exp(-B[i]*A[i]@x))) * B[i] * A[i]\n",
    "    return s\n",
    "grad_f = lambda x : -(1/m)*grad_sum(x) + 2 * Lambda * x\n",
    "\n",
    "def ggrad_sum(x):\n",
    "    s = 0\n",
    "    for i in range(m):\n",
    "        s += (1 - 1/(1+np.exp(-B[i]*A[i]@x))) * 1/(1+np.exp(-B[i]*A[i]@x)) * np.outer(A[i], A[i])\n",
    "ggrad_f = lambda x : -(1/m)*ggrad_sum(x) + 2*Lambda * np.eye(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trust_domain():\n",
    "    def __init__(self, f, grad_f, ggrad_f, step):\n",
    "        self.f = f\n",
    "        self.grad_f = grad_f\n",
    "        self.step = step\n",
    "        self.ggrad_f = ggrad_f\n",
    "\n",
    "    def _m(self, x, d, B, k):\n",
    "        return self.f(x[k]) + self.grad_f(x[k])@d + (1/2) * d@B@d\n",
    "\n",
    "    ## find s s.t. _m(d) = min{_m(d)}\n",
    "    def Steihaug_CG(self, x, Delta, B, k):\n",
    "        g = self.grad_f(x[k])\n",
    "        # init params\n",
    "        s = np.zeros((1,m))\n",
    "        r = g\n",
    "        p = -g\n",
    "        epsilon = 0.01   ## maybe there is a better choice \n",
    "        while(np.dot(r,r) < epsilon * np.dot(g,g)):\n",
    "            alpha = (np.dot(r,r))/(p@B@p)\n",
    "            s += alpha * p\n",
    "            if (np.sqrt(np.dot(s,s)) > Delta):\n",
    "                break\n",
    "            r_next = r + alpha * B@p\n",
    "            beta = np.dot(r_next,r_next)/np.dot(r,r)\n",
    "            p = -r_next + beta * p\n",
    "            r = r_next\n",
    "        return s\n",
    "    def solve(self):\n",
    "        Delta = np.sqrt(n)\n",
    "        x = np.zeros((self.step+1, m))\n",
    "        x_init = np.linspace(1, 10, m)\n",
    "        x[0] = x_init\n",
    "        rho1 = 0.25\n",
    "        rho2 = 0.75\n",
    "        gamma1 = 0.25\n",
    "        gamma2 = 2\n",
    "        for k in range(self.step):\n",
    "            B = self.ggrad_f(x[k])\n",
    "            d = self.Steihaug_CG(x, Delta, B, k)\n",
    "            rho = (self.f(x[k]) - self.f(x[k]+d))/(m(x, 0, B, k) - m(x, d, B, k))\n",
    "            if (rho < rho1):\n",
    "                Delta = gamma1 * Delta\n",
    "            elif (rho > rho2):\n",
    "                Delta = gamma2 * Delta\n",
    "            else:\n",
    "                Delta = Delta\n",
    "            x[k+1] = x[k] + d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
