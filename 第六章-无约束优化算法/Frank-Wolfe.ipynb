{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "# IMPLEMENTATION OF THE FRANK-WOLFE ALGORITHM\n",
    "# In this file, we define the functions required for the implementation of the algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frank-Wolfe 算法求解 Lasso 问题：\n",
    "\n",
    "1. 定义函数 $f(x, A, y)$:\n",
    "$$\n",
    "f(x) = |Ax-y|^2\n",
    "$$\n",
    "见代码 def f(x, A, y)\n",
    "\n",
    "2. 定义函数的梯度 $∇f(x, A, y)$:\n",
    "$$\n",
    "∇f(x) = 2AT(Ax−y)\n",
    "$$\n",
    "\n",
    "3. Oracle 步骤:\n",
    "$$\n",
    "s=\\arg\\min_{y\\in D}\\langle\\nabla f(x_k),y-x_k\\rangle \n",
    "$$\n",
    "其实就是找 $∇f(x)$ 中绝对值最大的元素, 见代码 fwOracle.\n",
    "\n",
    "4. update 步骤:\n",
    "$$\n",
    "x_{k+1}=(1-\\rho_k)x_k+\\rho_ks\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Define the function f(x)\n",
    "def f(x, A, y):\n",
    "    \"\"\"\n",
    "    Function that computes the f(x) defined as: |Ax - y|^2\n",
    "    :param x: (p, 1) numpy vector\n",
    "                Data vector\n",
    "    :param A: (n, p) numpy matrix\n",
    "                Design matrix of the LASSO problem\n",
    "    :param y: (n, ) numpy vector\n",
    "                Target vector of the LASSO problem\n",
    "    :return: f(x), scalar, evaluated as defined above\n",
    "    \"\"\"\n",
    "    return np.matmul((np.matmul(A, x) - y).transpose(), np.matmul(A, x) - y)\n",
    "\n",
    "\n",
    "# %% Define function to compute gradient\n",
    "def gradient(x, A, y):\n",
    "    \"\"\"\n",
    "    Function that computes the gradient of f(x) defined as: 2 * (A.T(Ax - y))\n",
    "    :param x: same as defined in previous function\n",
    "    :param A: same as defined in previous function\n",
    "    :param y: same as defined in previous function\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return 2 * np.matmul(A.transpose(), np.matmul(A, x) - y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "求解 Lasso 问题，一般需要正则化:\n",
    "$$\n",
    "loss = loss + l|x|\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Define function to find a point in the Oracle\n",
    "def fwOracle(gradient, l):\n",
    "    \"\"\"\n",
    "    Function that computes the Frank-Wolfe Oracle defined as:\n",
    "        argmin(s) <gradient(f(x)), s> where s in the feasible\n",
    "        set D and < > is the inner product.\n",
    "    :param gradient: (p, 1) numpy vector\n",
    "                Should be the gradient of f(x)\n",
    "    :param l: (lambda) a scalar > 0\n",
    "                Penalty parameter of the LASSO problem\n",
    "    :return: s: (p, 1) numpy vector\n",
    "                FW Oracle as defined above\n",
    "    \"\"\"\n",
    "    # Initialize the zero vector\n",
    "    s = np.zeros((p, 1))\n",
    "\n",
    "    # Check if all coordinates of x are 0\n",
    "    # If they are, then the Oracle contains zero vector\n",
    "    if (gradient != 0).sum() == 0:\n",
    "        return s\n",
    "\n",
    "    # Otherwise, follow the following steps\n",
    "    else:\n",
    "        # Compute the (element-wise) absolute value of x\n",
    "        a = abs(gradient)\n",
    "        # Find the first coordinate that has the maximum absolute value\n",
    "        i = np.nonzero(a == max(a))[0][0]\n",
    "        # Compute s\n",
    "        s[i] = - np.sign(gradient[i]) * l\n",
    "        return s\n",
    "\n",
    "## xk+1 = xk + grad(f(xk))      grad(f) = [g1,g2,...,gn]    假设 gi 最大 s = [0,0,...., gi,..,0]\n",
    "## xk+1 = xk + s\n",
    "\n",
    "\n",
    "#%% Define function for applying the Frank-Wolfe algorithm to solve LASSO problem\n",
    "def frankWolfeLASSO(A, y, l=500, tol=0.0001, K=15000):\n",
    "    \"\"\"\n",
    "    Function that applies the Frank-Wolfe algorithm on a LASSO problem, given\n",
    "    the required x, A, y and K.\n",
    "    :param A: (n, p) numpy matrix\n",
    "                Design matrix of the LASSO problem\n",
    "    :param y: (n, ) numpy vector\n",
    "                Target vector of the LASSO problem\n",
    "    :param K: integer > 0\n",
    "                Maximum number of iterations\n",
    "    :param l: integer > 0\n",
    "                Regularization parameter\n",
    "    :param tol: float > 0\n",
    "                    Tolerance rate of the error ||f(x_k) - f(x_(k-1))||\n",
    "    :return: data: f(x): K-dimensional numpy vector\n",
    "                argmin(D) of f\n",
    "            diffx: (K-1)-dimensional numpy vector\n",
    "                difference ||f(x_k) - f(x_(k-1))||\n",
    "            k: integer > 0\n",
    "                The number of iterations made\n",
    "    \"\"\"\n",
    "    # Initialise:\n",
    "    # x : sequence of K data points\n",
    "    #       (each being a p-dimensional vector of features)\n",
    "    # s : sequence of K \"oracles\"\n",
    "    #       (each being a p-dimensional vector)\n",
    "    # rho : step-size sequence having K elements\n",
    "    # data : K-dimensional vector of resulting data points\n",
    "    # data : (K-1)-dimensional vector of the difference f(x_k) - f(x_(k-1))\n",
    "    # x[0] and s[0] to p-dimensional vectors of zeros (starting points)\n",
    "    x = [None] * K\n",
    "    s = [None] * K\n",
    "    rho = [None] * K\n",
    "    data = [None] * K\n",
    "    diffx = [None] * K\n",
    "    p = np.shape(A)[1]\n",
    "    x[0] = np.zeros((p, 1))\n",
    "    s[0] = np.zeros((p, 1))\n",
    "\n",
    "    # Apply the Frank-Wolfe Algorithm\n",
    "    for k in range(1, K):\n",
    "        rho[k] = 2 / (2 + k)\n",
    "        s[k] = fwOracle(gradient(x[k - 1], A, y), l)\n",
    "        x[k] = (1 - rho[k]) * x[k - 1] + rho[k] * s[k]\n",
    "        data[k] = f(x[k], A, y)\n",
    "        if k > 1:\n",
    "            diffx[k - 1] = data[k] - data[k - 1]\n",
    "            if tol >= abs(diffx[k - 1]): break\n",
    "\n",
    "    # Return\n",
    "    return data, diffx, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataToPlot = pd.DataFrame({\n",
    "    \"epsilon\" : np.array([0.1, 0.01, 0.001, 0.0001]),\n",
    "    \"k1\" : np.zeros(4),\n",
    "    \"k2\" : np.zeros(4),\n",
    "    \"k3\" : np.zeros(4)\n",
    "})\n",
    "\n",
    "# CASE 1: l = 50, n = 1000, p = 700\n",
    "# Array that will hold the returned numbers of iterations for each level of \n",
    "# tolerance.\n",
    "returnedK = np.zeros(4)\n",
    "# Array that will hold the returned data (f(x))\n",
    "data = [None] * 4\n",
    "# Array that will hold the norm of the difference: ||f(x_k) - (f_(k-1))\n",
    "diffx = [None] * 4\n",
    "n = 1000  # number of observations\n",
    "p = 700   # number of parameters\n",
    "l = 50    # penalty parameter\n",
    "A, y = datasets.make_regression(n, p)\n",
    "y = y.reshape((n, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#%% First round of testing of our implementation:\n",
    "# We fix the number of obseverations (n) and the number of parameters (p)\n",
    "# and study the performance of the algorithm when only lambda (l) is changing.\n",
    "\n",
    "# Array holding the tolerance levels we will be working with\n",
    "epsilon = np.array([0.1, 0.01, 0.001, 0.0001])\n",
    "\n",
    "# Pandas dataframe that will hold the data used to create the plot\n",
    "dataToPlot = pd.DataFrame({\n",
    "    \"epsilon\" : np.array([0.1, 0.01, 0.001, 0.0001]),\n",
    "    \"k1\" : np.zeros(4),\n",
    "    \"k2\" : np.zeros(4),\n",
    "    \"k3\" : np.zeros(4)\n",
    "})\n",
    "\n",
    "# CASE 1: l = 50, n = 1000, p = 700\n",
    "# Array that will hold the returned numbers of iterations for each level of \n",
    "# tolerance.\n",
    "returnedK = np.zeros(4)\n",
    "# Array that will hold the returned data (f(x))\n",
    "data = [None] * 4\n",
    "# Array that will hold the norm of the difference: ||f(x_k) - (f_(k-1))\n",
    "diffx = [None] * 4\n",
    "n = 1000  # number of observations\n",
    "p = 700   # number of parameters\n",
    "l = 50    # penalty parameter\n",
    "A, y = datasets.make_regression(n, p)\n",
    "y = y.reshape((n, 1))\n",
    "\n",
    "#print(\"case 1:-------------------------------------------\")\n",
    "for i in range(4):\n",
    "    print(i)\n",
    "    data[i], diffx[i], dataToPlot.loc[i, 'k1'] = \\\n",
    "      frankWolfeLASSO(A, y, l=50, tol=epsilon[i])\n",
    "\n",
    "\n",
    "# CASE 2: l = 500, n = 1000, p = 700\n",
    "returnedK = np.zeros(4)\n",
    "data = [None] * 4\n",
    "diffx = [None] * 4\n",
    "n = 1000\n",
    "p = 700\n",
    "l = 500\n",
    "A, y = datasets.make_regression(n, p)\n",
    "y = y.reshape((n, 1))\n",
    "\n",
    "#print(\"case 2:-------------------------------------------\")\n",
    "for i in range(4):\n",
    "    print(i)\n",
    "    data[i], diffx[i], dataToPlot.loc[i, 'k2'] = \\\n",
    "        frankWolfeLASSO(A, y, l=l, tol=epsilon[i])\n",
    "\n",
    "\n",
    "# CASE 3: l = 5000, n = 1000, p = 700\n",
    "returnedK = np.zeros(4)\n",
    "data = [None] * 4\n",
    "diffx = [None] * 4\n",
    "n = 1000\n",
    "p = 700\n",
    "l = 5000\n",
    "A, y = datasets.make_regression(n, p)\n",
    "y = y.reshape((n, 1))\n",
    "\n",
    "#print(\"case 3:-------------------------------------------\")\n",
    "for i in range(4):\n",
    "    print(i)\n",
    "    data[i], diffx[i], dataToPlot.loc[i, 'k3'] = \\\n",
    "        frankWolfeLASSO(A, y, l=l, tol=epsilon[i])\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(dataToPlot.epsilon, dataToPlot.k1, marker=\"o\", color=\"darkgreen\",\\\n",
    "              label = \"l = 50\")\n",
    "plt.plot(dataToPlot.epsilon, dataToPlot.k2, marker=\"o\", color=\"deepskyblue\", \\\n",
    "              label = \"l = 500\")\n",
    "plt.plot(dataToPlot.epsilon, dataToPlot.k3, marker=\"o\", color=\"firebrick\", \\\n",
    "              label = \"l = 5000\")\n",
    "plt.legend()\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.suptitle(\"Solving LASSO problem using Frank-Wolfe Algorithm\", fontsize=16)\n",
    "plt.xlabel(\"Tolerance level\")\n",
    "plt.ylabel(\"Number of iterations (k)\")\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.savefig(\"Question6b_toleranceIterations_l.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epsilon</th>\n",
       "      <th>k1</th>\n",
       "      <th>k2</th>\n",
       "      <th>k3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>369.0</td>\n",
       "      <td>2043.0</td>\n",
       "      <td>2996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>2043.0</td>\n",
       "      <td>14999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>3128.0</td>\n",
       "      <td>11301.0</td>\n",
       "      <td>14999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>5905.0</td>\n",
       "      <td>14999.0</td>\n",
       "      <td>14999.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epsilon      k1       k2       k3\n",
       "0   0.1000   369.0   2043.0   2996.0\n",
       "1   0.0100  1205.0   2043.0  14999.0\n",
       "2   0.0010  3128.0  11301.0  14999.0\n",
       "3   0.0001  5905.0  14999.0  14999.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataToPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
